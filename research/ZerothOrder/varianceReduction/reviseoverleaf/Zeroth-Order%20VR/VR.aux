\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{ji2019improved}
\citation{johnson2013accelerating,reddi2016stochastic,nitanda2016accelerated,allen2016improved,lei2017non}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}what we want to do}{1}{subsection.1.1}}
\newlabel{problem}{{1}{1}{what we want to do}{equation.1.1}{}}
\citation{nesterov2013gradient}
\citation{xiao2014proximal,defazio2014saga,lan2017optimal,allen2017katyusha}
\citation{beck2009fast}
\citation{xiao2014proximal}
\citation{bertsekas2011incremental,xiao2014proximal}
\citation{li2015accelerated}
\citation{ghadimi2016accelerated,reddi2016proximal}
\citation{li2018simple}
\citation{reddi2016proximal}
\citation{wibisono2012finite}
\citation{sokolov2016stochastic}
\citation{shamir2017optimal}
\citation{chen2017zoo}
\citation{nesterov2017random}
\citation{brent2013algorithms,spall2005introduction}
\citation{kurakin2016adversarial,papernot2017practical,chen2017zoo}
\citation{choromanski2018structured}
\citation{taskar2005learning}
\citation{chen2019bandit,liu2017zeroth}
\citation{fu2002optimization,lian2016comprehensive}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Background in research}{2}{subsection.1.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}Reason to use zeroth--order techniques}{2}{subsection.1.3}}
\citation{liu2017zeroth,flaxman2005online,shamir2013complexity,agarwal2010optimal,nesterov2017random,duchi2015optimal,shamir2017optimal,dvurechensky2018accelerated,wang2017stochastic}
\citation{liu2018stochastic,liu2018zeroth}
\citation{johnson2013accelerating}
\citation{liu2018zeroth}
\citation{ghadimi2016accelerated}
\citation{huang2019faster}
\citation{ghadimi2016accelerated}
\citation{ji2019improved}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4}Problem with existing methods}{3}{subsection.1.4}}
\citation{liu2018zeroth,ji2019improved}
\citation{liu2018zeroth}
\citation{ghadimi2016accelerated,huang2019faster}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.5}Compare with other methods}{4}{subsection.1.5}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Main Challenge}{4}{section.2}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Main contributions}{4}{section.3}}
\citation{ghadimi2016accelerated}
\citation{huang2019faster}
\citation{ji2019improved}
\citation{liu2018zeroth,ji2019improved}
\citation{polyak1963gradient}
\citation{duchi2015optimal}
\citation{ji2019improved}
\citation{flaxman2005online,shamir2013complexity}
\citation{agarwal2010optimal,nesterov2017random}
\citation{nesterov2017random}
\citation{duchi2015optimal}
\citation{yu2018generic,dvurechensky2018accelerated}
\citation{chen2017zoo,liu2018zeroth}
\citation{ghadimi2013stochastic}
\citation{nesterov2011random}
\citation{liu2018stochastic}
\citation{liu2018zeroth}
\citation{ji2019improved}
\citation{liu2018zeroth}
\citation{huang2019faster}
\citation{reddi2016proximal}
\citation{ghadimi2016accelerated}
\citation{liu2018stochastic}
\citation{gu2018inexact,lian2016comprehensive,gu2018faster}
\citation{lian2016comprehensive}
\citation{gu2018faster}
\citation{nesterov2017random}
\citation{ghadimi2016accelerated}
\citation{liu2018zeroth}
\citation{ji2019improved}
\citation{gu2018faster}
\citation{gu2018faster}
\@writefile{toc}{\contentsline {section}{\numberline {4}Related Works}{6}{section.4}}
\citation{nesterov2017random,gao2018information}
\citation{flaxman2005online,shamir2017optimal,gao2018information}
\citation{lian2016comprehensive}
\citation{gu2018inexact,gu2018faster,liu2018zeroth}
\newlabel{table-compare}{{4}{7}{Related Works}{section.4}{}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Summary of convergence rate and function query complexity of SZO algorithms. S: Smooth, NS: Nonsmooth, NC: Nonconvex, C: Convex, SC: Strong Convexity, and PL: Polyak-\IeC {\L }ojasiewicz Condition. $s_n = \qopname  \relax m{min}\{n, \frac  {1}{\epsilon }\}$}}{7}{table.1}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Preliminary}{7}{section.5}}
\newlabel{gradestrand}{{2}{7}{Preliminary}{equation.5.2}{}}
\citation{kazemi2018proximal}
\citation{ghadimi2013stochastic,reddi2016stochastic,lei2017non,liu2018zeroth}
\citation{ghadimi2016accelerated,reddi2016proximal,huang2019faster}
\citation{ghadimi2016accelerated,reddi2016proximal,parikh2014proximal}
\newlabel{gradestcoord}{{3}{8}{Preliminary}{equation.5.3}{}}
\newlabel{po-operator}{{5}{8}{Preliminary}{equation.5.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Gradient Mapping}{8}{subsection.5.1}}
\citation{xiao2014proximal,reddi2016proximal,li2018simple}
\@writefile{toc}{\contentsline {section}{\numberline {6}ZO Proximal Stochastic Method (ZO-PSVRG+)}{9}{section.6}}
\newlabel{APGnonconvex-Algo}{{6}{9}{ZO Proximal Stochastic Method (ZO-PSVRG+)}{section.6}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces ZO-PSVRG+}}{9}{algorithm.1}}
\newlabel{grad-fo}{{7}{9}{ZO Proximal Stochastic Method (ZO-PSVRG+)}{equation.6.7}{}}
\citation{reddi2016proximal,li2018simple}
\citation{ghadimi2016accelerated,nesterov2017random,liu2018zeroth}
\citation{lian2016comprehensive,liu2018stochastic,liu2018zeroth,hajinezhad2017zeroth}
\citation{liu2017zeroth,hajinezhad2017zeroth}
\newlabel{zo-grad-fo}{{8}{10}{ZO Proximal Stochastic Method (ZO-PSVRG+)}{equation.6.8}{}}
\newlabel{zo-grad-fo-rand}{{9}{10}{ZO Proximal Stochastic Method (ZO-PSVRG+)}{equation.6.9}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7}Convergence Analysis}{10}{section.7}}
\newlabel{Lip-Zoo}{{7.1}{10}{}{theorem.7.1}{}}
\newlabel{Var-Zoo}{{7.2}{10}{}{theorem.7.2}{}}
\newlabel{var-estimate-lem}{{7.3}{11}{}{theorem.7.3}{}}
\newlabel{var-estimate-lem-1}{{11}{11}{Convergence Analysis}{equation.7.11}{}}
\newlabel{var-estimate-lem-2}{{12}{11}{Convergence Analysis}{equation.7.12}{}}
\newlabel{var-estimate-lem-3}{{13}{11}{Convergence Analysis}{equation.7.13}{}}
\newlabel{var-estimate-lem-3p}{{14}{12}{Convergence Analysis}{equation.7.14}{}}
\newlabel{var-estimate-lem-5}{{15}{12}{Convergence Analysis}{equation.7.15}{}}
\newlabel{var-estimate-lem-6}{{16}{12}{Convergence Analysis}{equation.7.16}{}}
\newlabel{var-estimate-lem-7}{{17}{12}{Convergence Analysis}{equation.7.17}{}}
\newlabel{young}{{20}{13}{Convergence Analysis}{equation.7.20}{}}
\newlabel{RandSGE-var-estimate-lem}{{7.4}{13}{}{theorem.7.4}{}}
\newlabel{RandSGE-var-estimate-lem-1}{{22}{13}{Convergence Analysis}{equation.7.22}{}}
\newlabel{RandSGE-var-estimate-lem-2}{{23}{13}{Convergence Analysis}{equation.7.23}{}}
\newlabel{RandSGE-var-estimate-lem-3}{{24}{14}{Convergence Analysis}{equation.7.24}{}}
\newlabel{RandSGE-var-estimate-lem-4}{{25}{14}{Convergence Analysis}{equation.7.25}{}}
\newlabel{RandSGE-var-estimate-lem-5}{{26}{14}{Convergence Analysis}{equation.7.26}{}}
\newlabel{RandSGE-var-estimate-lem-6p}{{27}{14}{Convergence Analysis}{equation.7.27}{}}
\newlabel{RandSGE-var-estimate-lem-6}{{28}{14}{Convergence Analysis}{equation.7.28}{}}
\newlabel{RandSGE-var-estimate-lem-7}{{29}{14}{Convergence Analysis}{equation.7.29}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1}Analysis for ZO-PSVRG+}{14}{subsection.7.1}}
\newlabel{noncon-zoo-coord}{{7.5}{14}{}{theorem.7.5}{}}
\newlabel{noncon-zoo-main}{{30}{14}{}{equation.7.30}{}}
\newlabel{eq16}{{31}{15}{Analysis for ZO-PSVRG+}{equation.7.31}{}}
\newlabel{eq17}{{32}{15}{Analysis for ZO-PSVRG+}{equation.7.32}{}}
\newlabel{eq18}{{33}{15}{Analysis for ZO-PSVRG+}{equation.7.33}{}}
\newlabel{eq19}{{34}{15}{Analysis for ZO-PSVRG+}{equation.7.34}{}}
\newlabel{eq25}{{35}{16}{Analysis for ZO-PSVRG+}{equation.7.35}{}}
\newlabel{theor1-31}{{36}{16}{Analysis for ZO-PSVRG+}{equation.7.36}{}}
\newlabel{theor1-32}{{37}{16}{Analysis for ZO-PSVRG+}{equation.7.37}{}}
\newlabel{theor1-34}{{38}{16}{Analysis for ZO-PSVRG+}{equation.7.38}{}}
\citation{reddi2016proximal}
\newlabel{theor1-35}{{39}{17}{Analysis for ZO-PSVRG+}{equation.7.39}{}}
\newlabel{theor1-eq36}{{40}{17}{Analysis for ZO-PSVRG+}{equation.7.40}{}}
\citation{gu2018faster}
\newlabel{corr11}{{7.6}{18}{}{theorem.7.6}{}}
\newlabel{SZO-call-nocon}{{41}{18}{}{equation.7.41}{}}
\newlabel{SZO-call-par-nocon}{{42}{18}{}{equation.7.42}{}}
\newlabel{theor1-eq37}{{43}{18}{Analysis for ZO-PSVRG+}{equation.7.43}{}}
\citation{ji2019improved}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2}Analysis for ZO-PSVRG+ (RandSGE)}{19}{subsection.7.2}}
\newlabel{noncon-zoo-rand}{{7.7}{19}{}{theorem.7.7}{}}
\newlabel{eq-noncon-zoo-rand}{{44}{19}{}{equation.7.44}{}}
\newlabel{corr11-rand}{{7.8}{19}{}{theorem.7.8}{}}
\newlabel{SZO-call-nocon-rand}{{45}{19}{}{equation.7.45}{}}
\newlabel{SZO-call-par-nocon-rand}{{46}{19}{}{equation.7.46}{}}
\citation{polyak1963gradient}
\citation{karimi2016linear}
\citation{li2018simple}
\citation{ji2019improved}
\@writefile{toc}{\contentsline {section}{\numberline {8}Convergence Under PL Condition}{20}{section.8}}
\newlabel{zo-pl-cond}{{48}{20}{Convergence Under PL Condition}{equation.8.48}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.1}ZO-PSVRG+ Under PL Condition}{20}{subsection.8.1}}
\newlabel{PL-Zoo}{{8.1}{20}{}{theorem.8.1}{}}
\newlabel{PL-eq-error}{{49}{20}{}{equation.8.49}{}}
\newlabel{theo2-eq44}{{50}{21}{ZO-PSVRG+ Under PL Condition}{equation.8.50}{}}
\newlabel{theo2-eq46}{{53}{21}{ZO-PSVRG+ Under PL Condition}{equation.8.53}{}}
\newlabel{theo2-eq47}{{54}{21}{ZO-PSVRG+ Under PL Condition}{equation.8.54}{}}
\newlabel{eq48}{{55}{22}{ZO-PSVRG+ Under PL Condition}{equation.8.55}{}}
\newlabel{eq50}{{56}{22}{ZO-PSVRG+ Under PL Condition}{equation.8.56}{}}
\newlabel{eq51}{{57}{22}{ZO-PSVRG+ Under PL Condition}{equation.8.57}{}}
\newlabel{eq52}{{58}{22}{ZO-PSVRG+ Under PL Condition}{equation.8.58}{}}
\citation{duchi2015optimal,nesterov2017random,liu2018zeroth}
\citation{reddi2016stochastic}
\citation{ji2019improved}
\newlabel{PL-Zo-Cor}{{8.2}{23}{}{theorem.8.2}{}}
\citation{reddi2016proximal}
\newlabel{eq54}{{60}{24}{}{equation.8.60}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.2}ZO-PSVRG+ (RandSGE) Under PL Condition}{24}{subsection.8.2}}
\newlabel{PL-Zoo-rand}{{8.4}{24}{}{theorem.8.4}{}}
\newlabel{PL-eq-error-rand}{{61}{24}{}{equation.8.61}{}}
\newlabel{PL-Zo-Cor-rand}{{8.5}{24}{}{theorem.8.5}{}}
\citation{ji2019improved}
\citation{gu2018faster}
\citation{ghadimi2016accelerated}
\@writefile{toc}{\contentsline {section}{\numberline {9}Experimental Results}{25}{section.9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.1}Black-Box Binary Classification}{25}{subsection.9.1}}
\citation{chen2017zoo,liu2018zeroth}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Summary of training datasets.}}{26}{table.2}}
\newlabel{metadata}{{2}{26}{Summary of training datasets}{table.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.2}Adversarial Attacks on Black-Box DNNs}{26}{subsection.9.2}}
\newlabel{binary-fig}{{9.1}{27}{Black-Box Binary Classification}{table.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Comparison of different zeroth-order algorithms for logistic regression loss residual $f(x) - f(x^*)$ versus the number of epochs (top) and ZO queries (bottom)}}{27}{figure.1}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {ijcnn}}}{27}{figure.1}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {comparison on covtype}}}{27}{figure.1}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {w8a}}}{27}{figure.1}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(d)}{\ignorespaces {mnist}}}{27}{figure.1}}
\newlabel{fig:algo_comp}{{1}{27}{Comparison of different zeroth-order algorithms for logistic regression loss residual $f(x) - f(x^*)$ versus the number of epochs (top) and ZO queries (bottom)}{figure.1}{}}
\newlabel{mnist-attack-loss}{{63}{27}{Adversarial Attacks on Black-Box DNNs}{equation.9.63}{}}
\citation{liu2018zeroth}
\citation{gao2018information}
\citation{ji2019improved}
\newlabel{attack-fig}{{9.2}{28}{Adversarial Attacks on Black-Box DNNs}{equation.9.63}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Comparison of different zeroth-order algorithms for generating black-box adversarial examples from a black-box DNN}}{28}{figure.2}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Loss vs iterations: $n = 10$}}}{28}{figure.2}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Loss vs queries: $n = 10$}}}{28}{figure.2}}
\@writefile{toc}{\contentsline {section}{\numberline {10}Appendix}{28}{section.10}}
\newlabel{CooSGE}{{10.1}{28}{\cite {liu2018zeroth}}{theorem.10.1}{}}
\newlabel{SGERand-approx}{{10.2}{28}{}{theorem.10.2}{}}
\newlabel{lemma1}{{10.3}{29}{}{theorem.10.3}{}}
\newlabel{eq10}{{64}{29}{}{equation.10.64}{}}
\newlabel{eq11}{{65}{29}{Appendix}{equation.10.65}{}}
\newlabel{eq12}{{66}{29}{Appendix}{equation.10.66}{}}
\newlabel{eq14}{{67}{29}{Appendix}{equation.10.67}{}}
\newlabel{eq15}{{68}{29}{Appendix}{equation.10.68}{}}
\newlabel{lemm-est-grad}{{10.4}{29}{}{theorem.10.4}{}}
\newlabel{lemm-est-grad-1}{{69}{29}{Appendix}{equation.10.69}{}}
\newlabel{lemm-est-grad-2}{{70}{29}{Appendix}{equation.10.70}{}}
\bibstyle{plainnat}
\bibdata{GTA}
\bibcite{agarwal2010optimal}{{1}{2010}{{Agarwal et~al.}}{{Agarwal, Dekel, and Xiao}}}
\bibcite{allen2017katyusha}{{2}{2017}{{Allen-Zhu}}{{}}}
\bibcite{allen2016improved}{{3}{2016}{{Allen-Zhu and Yuan}}{{}}}
\bibcite{anitescu2000degenerate}{{4}{2000}{{Anitescu}}{{}}}
\bibcite{beck2009fast}{{5}{2009}{{Beck and Teboulle}}{{}}}
\bibcite{bertsekas2011incremental}{{6}{2011}{{Bertsekas}}{{}}}
\bibcite{brent2013algorithms}{{7}{2013}{{Brent}}{{}}}
\bibcite{chen2017zoo}{{8}{2017}{{Chen et~al.}}{{Chen, Zhang, Sharma, Yi, and Hsieh}}}
\bibcite{chen2019bandit}{{9}{2019}{{Chen and Giannakis}}{{}}}
\bibcite{choromanski2018structured}{{10}{2018}{{Choromanski et~al.}}{{Choromanski, Rowland, Sindhwani, Turner, and Weller}}}
\bibcite{defazio2014saga}{{11}{2014}{{Defazio et~al.}}{{Defazio, Bach, and Lacoste-Julien}}}
\newlabel{lemm-est-grad-3}{{71}{30}{Appendix}{equation.10.71}{}}
\newlabel{lemm-est-grad-4}{{72}{30}{Appendix}{equation.10.72}{}}
\bibcite{duchi2015optimal}{{12}{2015}{{Duchi et~al.}}{{Duchi, Jordan, Wainwright, and Wibisono}}}
\bibcite{dvurechensky2018accelerated}{{13}{2018}{{Dvurechensky et~al.}}{{Dvurechensky, Gasnikov, and Gorbunov}}}
\bibcite{flaxman2005online}{{14}{2005}{{Flaxman et~al.}}{{Flaxman, Kalai, and McMahan}}}
\bibcite{fu2002optimization}{{15}{2002}{{Fu}}{{}}}
\bibcite{gao2018information}{{16}{2018}{{Gao et~al.}}{{Gao, Jiang, and Zhang}}}
\bibcite{ghadimi2013stochastic}{{17}{2013}{{Ghadimi and Lan}}{{}}}
\bibcite{ghadimi2016accelerated}{{18}{2016}{{Ghadimi and Lan}}{{}}}
\bibcite{gu2018faster}{{19}{2018{a}}{{Gu et~al.}}{{Gu, Huo, Deng, and Huang}}}
\bibcite{gu2018inexact}{{20}{2018{b}}{{Gu et~al.}}{{Gu, Wang, Huo, and Huang}}}
\bibcite{hajinezhad2017zeroth}{{21}{2017}{{Hajinezhad et~al.}}{{Hajinezhad, Hong, and Garcia}}}
\bibcite{huang2019faster}{{22}{2019}{{Huang et~al.}}{{Huang, Gu, Huo, Chen, and Huang}}}
\bibcite{ji2019improved}{{23}{2019}{{Ji et~al.}}{{Ji, Wang, Zhou, and Liang}}}
\bibcite{johnson2013accelerating}{{24}{2013}{{Johnson and Zhang}}{{}}}
\bibcite{karimi2016linear}{{25}{2016}{{Karimi et~al.}}{{Karimi, Nutini, and Schmidt}}}
\bibcite{kazemi2018proximal}{{26}{2018}{{Kazemi and Wang}}{{}}}
\bibcite{kurakin2016adversarial}{{27}{2016}{{Kurakin et~al.}}{{Kurakin, Goodfellow, and Bengio}}}
\bibcite{lan2017optimal}{{28}{2017}{{Lan and Zhou}}{{}}}
\bibcite{lei2017non}{{29}{2017}{{Lei et~al.}}{{Lei, Ju, Chen, and Jordan}}}
\bibcite{li2015accelerated}{{30}{2015}{{Li and Lin}}{{}}}
\bibcite{li2018simple}{{31}{2018}{{Li and Li}}{{}}}
\bibcite{lian2016comprehensive}{{32}{2016}{{Lian et~al.}}{{Lian, Zhang, Hsieh, Huang, and Liu}}}
\bibcite{liu2018stochastic}{{33}{2018{a}}{{Liu et~al.}}{{Liu, Cheng, Hsieh, and Tao}}}
\bibcite{liu2017zeroth}{{34}{2017}{{Liu et~al.}}{{Liu, Chen, Chen, and Hero}}}
\bibcite{liu2018zeroth}{{35}{2018{b}}{{Liu et~al.}}{{Liu, Kailkhura, Chen, Ting, Chang, and Amini}}}
\bibcite{luo1993error}{{36}{1993}{{Luo and Tseng}}{{}}}
\bibcite{nesterov2013gradient}{{37}{2013}{{Nesterov}}{{}}}
\bibcite{nesterov2011random}{{38}{2011}{{Nesterov and Spokoiny}}{{}}}
\bibcite{nesterov2017random}{{39}{2017}{{Nesterov and Spokoiny}}{{}}}
\bibcite{nitanda2016accelerated}{{40}{2016}{{Nitanda}}{{}}}
\bibcite{papernot2017practical}{{41}{2017}{{Papernot et~al.}}{{Papernot, McDaniel, Goodfellow, Jha, Celik, and Swami}}}
\bibcite{parikh2014proximal}{{42}{2014}{{Parikh et~al.}}{{Parikh, Boyd, et~al.}}}
\bibcite{polyak1963gradient}{{43}{1963}{{Polyak}}{{}}}
\bibcite{reddi2016stochastic}{{44}{2016{a}}{{Reddi et~al.}}{{Reddi, Hefny, Sra, Poczos, and Smola}}}
\bibcite{reddi2016proximal}{{45}{2016{b}}{{Reddi et~al.}}{{Reddi, Sra, P{\'o}czos, and Smola}}}
\bibcite{shamir2013complexity}{{46}{2013}{{Shamir}}{{}}}
\bibcite{shamir2017optimal}{{47}{2017}{{Shamir}}{{}}}
\bibcite{sokolov2016stochastic}{{48}{2016}{{Sokolov et~al.}}{{Sokolov, Kreutzer, Riezler, and Lo}}}
\bibcite{spall2005introduction}{{49}{2005}{{Spall}}{{}}}
\bibcite{taskar2005learning}{{50}{2005}{{Taskar et~al.}}{{Taskar, Chatalbashev, Koller, and Guestrin}}}
\bibcite{wang2017stochastic}{{51}{2017}{{Wang et~al.}}{{Wang, Du, Balakrishnan, and Singh}}}
\bibcite{wibisono2012finite}{{52}{2012}{{Wibisono et~al.}}{{Wibisono, Wainwright, Jordan, and Duchi}}}
\bibcite{xiao2014proximal}{{53}{2014}{{Xiao and Zhang}}{{}}}
\bibcite{yu2018generic}{{54}{2018}{{Yu et~al.}}{{Yu, King, Lyu, and Yang}}}
